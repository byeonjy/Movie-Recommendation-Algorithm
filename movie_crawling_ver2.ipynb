{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"movie_crawling_ver2.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"eAS7GZUhpSgK","outputId":"a8fbe11d-931a-4cd5-a342-54493bc46d03"},"source":["import pandas as pd\n","from selenium import webdriver\n","from bs4 import BeautifulSoup\n","import time\n","import sys\n","import os\n","import xlwt\n","import math\n","from datetime import datetime\n","\n","print('=' * 80)\n","print('네이버 영화 리뷰 수집하기')\n","print('\"%s\" 폴더에 chromedriver.exe 파일을 위치시켜주세요.'%os.getcwd())\n","print('=' * 80)\n","print('\\n')\n","\n","df_title = pd.DataFrame()\n","tmp_title = []"],"execution_count":null,"outputs":[{"output_type":"stream","text":["================================================================================\n","네이버 영화 리뷰 수집하기\n","\"C:\\Users\\adm\\Downloads\\crawling\" 폴더에 chromedriver.exe 파일을 위치시켜주세요.\n","================================================================================\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MKT3_CKDpSga"},"source":["\n","input_url = input('크롤링할 영화 url을 입력하세요: ')\n","input_num = 100\n","input_path = '용기'\n","if(input_path == '0'):\n","    input_path = os.getcwd()\n","\n","driver = webdriver.Chrome(os.getcwd() + \"/chromedriver.exe\")\n","driver.get(input_url)\n","\n","score = []\n","text = []\n","user = []\n","date = []\n","good = []\n","bad = []\n","gerne = []\n","director = []\n","runtime = []\n","\n","driver.get(input_url)\n","driver.switch_to_default_content()\n","\n","full_html = driver.page_source\n","soup = BeautifulSoup(full_html, 'html.parser')\n","\n","input_title = soup.find('h3', class_='h_movie').find('a').text\n","tmp_moviescore1 = soup.find('div',class_='score score_left').find('div',class_='star_score').find_all('em')[0].text\n","tmp_moviescore2 = soup.find('div',class_='score score_left').find('div',class_='star_score').find_all('em')[1].text\n","tmp_moviescore3 = soup.find('div',class_='score score_left').find('div',class_='star_score').find_all('em')[2].text\n","tmp_moviescore4 = soup.find('div',class_='score score_left').find('div',class_='star_score').find_all('em')[3].text\n","moviescore = tmp_moviescore1 + tmp_moviescore2 + tmp_moviescore3 + tmp_moviescore4\n","info_gr = soup.find('dl', class_='info_spec').find('dd').find('p').find_all('span')\n","gerne = info_gr[0].text\n","runtime = info_gr[2].text\n","director = soup.find('dl', class_='info_spec').find_all('dd')[1].find('p').find('a').text\n","\n","tmp_title.append(input_title)\n","        \n","driver.switch_to_default_content()\n","driver.switch_to_frame('pointAfterListIframe')\n","\n","full_html = driver.page_source\n","soup = BeautifulSoup(full_html, 'html.parser')\n","\n","count = 0\n","\n","f_txt = input_path + '/' + input_title + '.txt'\n","f_csv = input_path + '/' + input_title + '.csv'\n","f_xls = input_path + '/' + input_title + '.xls'\n","\n","while(True):\n","    content_list =  soup.find('div',class_='ifr_area basic_ifr').find('div', class_ = 'score_result').find('ul').find_all('li')\n","    print(type(content_list))\n","    for li in content_list:\n","        print('--------\\n',li)\n","        count += 1\n","\n","        tmp_score = li.find('div', class_='star_score').find('em').text\n","        tmp_text = li.find('div', class_='score_reple').find('p').text\n","        tmp_user = li.find('div', class_='score_reple').find('dl').find('span').text\n","        tmp_date = li.find('div', class_='score_reple').find_all('em')[1].text\n","        tmp_good = li.find('div', class_='btn_area').find_all('strong')[0].text\n","        tmp_bad = li.find('div', class_='btn_area').find_all('strong')[1].text\n","\n","\n","        score.append(tmp_score)\n","        text.append(tmp_text)\n","        user.append(tmp_user)\n","        date.append(tmp_date)\n","        good.append(tmp_good)\n","        bad.append(tmp_bad)\n","\n","        if(count == input_num):\n","            break\n","    \n","    if(count == input_num):\n","        break\n","    \n","    else:\n","        driver.find_element_by_class_name('pg_next').click()\n","        time.sleep(1)\n","                \n","        driver.switch_to_default_content()\n","        driver.switch_to_frame('pointAfterListIframe')\n","\n","        full_html = driver.page_source\n","        soup = BeautifulSoup(full_html, 'html.parser')\n","        \n","df = pd.DataFrame()\n","df['별점'] = score\n","df['리뷰내용'] = text\n","df['작성자'] = user\n","df['작성일자'] = date\n","df['공감'] = good\n","df['비공감'] = bad\n","df['영화제목'] = input_title\n","df['카테고리'] = input_path\n","df['장르'] = gerne\n","df['감독'] = director\n","df['상영시간'] = runtime\n","df['영화평점'] = moviescore\n","\n","df.to_csv(f_csv,encoding=\"utf-8-sig\",index=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gL1pfQFcpSgd"},"source":["df_title['영화제목'] = tmp_title\n","df_title.to_csv('영화제목목록.csv',encoding=\"utf-8-sig\",index=False)"],"execution_count":null,"outputs":[]}]}